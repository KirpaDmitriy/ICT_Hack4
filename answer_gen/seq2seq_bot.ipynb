{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xhSCyy2BpoBj",
    "outputId": "27eedf05-cee7-455b-8b2a-a15145c63cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May 21 12:57:34 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 441.37       Driver Version: 441.37       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX230      WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   57C    P8    N/A /  N/A |     63MiB /  2048MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pI5nKY8JpoBn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkSgEe-Jku-r"
   },
   "source": [
    "# Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QNNAb0a9kuEE"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3v2Ww3lkf9x"
   },
   "source": [
    "В этом проекте мы будем учиться делать перевод с французского на английский. Примерно так:\n",
    "\n",
    "    [KEY: > input, = target, < output]\n",
    "\n",
    "    > il est en train de peindre un tableau .\n",
    "    = he is painting a picture .\n",
    "    < he is painting a picture .\n",
    "\n",
    "    > pourquoi ne pas essayer ce vin delicieux ?\n",
    "    = why not try that delicious wine ?\n",
    "    < why not try that delicious wine ?\n",
    "\n",
    "    > elle n est pas poete mais romanciere .\n",
    "    = she is not a poet but a novelist .\n",
    "    < she not not a poet but a novelist .\n",
    "\n",
    "    > vous etes trop maigre .\n",
    "    = you re too skinny .\n",
    "    < you re all alone .\n",
    "\n",
    "Для этого мы будем исплользовать мощную идею «sequence-to-sequence» сетей (https://arxiv.org/abs/1409.3215), в которых две рекуррентные сети обучаются вместе для преоразования одной последовательности в другую.\n",
    "\n",
    "* Encoder-сеть сжимает входную последовательность в вектор.\n",
    "* Decoder-сеть разжимает этот вектор в новую последовательность.\n",
    "\n",
    "Всё как с автоэнкодерами, только encoder и decoder из разных доменов.\n",
    "\n",
    "Чтобы вся эта схема обучалась стабильнее, мы будем использовать механизм attention (https://arxiv.org/abs/1409.0473), позволяющий декодеру «фокусироваться» на специфичных токенах входной последовательности.\n",
    "\n",
    "**Рекомендуемое чтение:**\n",
    "\n",
    "-  Learning Phrase Representations using RNN Encoder-Decoder for\n",
    "   Statistical Machine Translation (https://arxiv.org/abs/1406.1078)\n",
    "-  Sequence to Sequence Learning with Neural\n",
    "   Networks (https://arxiv.org/abs/1409.3215)\n",
    "-  Neural Machine Translation by Jointly Learning to Align and\n",
    "   Translate 9https://arxiv.org/abs/1409.0473)\n",
    "-  A Neural Conversational Model (https://arxiv.org/abs/1506.05869>)\n",
    "\n",
    "Если кто-то пропустил предыдущие занатия, то лучше сначала сделать их: основные концепции такие же, как в языковых моделях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zt1ZcvSZkf9y"
   },
   "outputs": [],
   "source": [
    "# осторожно: тетрадка старая\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LENGTH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_A9f1xpMkf90"
   },
   "source": [
    "## Данные\n",
    "\n",
    "В этом проекте мы будем работать с кучей пар предложений на английском и французском.\n",
    "\n",
    "Скачайте данные отсюда (https://download.pytorch.org/tutorial/data.zip) и возьмите оттуда файлик eng-fra.txt. В нём должно быть много строчек примерно такого формата:\n",
    "\n",
    "    I am cold.    J'ai froid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pAoNlcCkf92"
   },
   "source": [
    "Делать предобработку будем по аналогии с char-level RNN-ками из предыдущих туториалов, только на этот раз нам важно отдельно запариться с EOS (end-of-sequence) — специальным токеном, который сеть будет генерировать при окончании генерации предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zYgxYCIZkf93"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def __repr__(self):\n",
    "        most_popular_words = sorted(\n",
    "            self.word2count.keys(), key=lambda word: self.word2count[word], reverse=True\n",
    "        )[:10]\n",
    "        most_popular_words = \", \".join(most_popular_words)\n",
    "        return f\"Language: {self.name} | Num words: {self.n_words} | Most popular: {most_popular_words}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G--d0a55kf95"
   },
   "source": [
    "Все файлы в юникоде. Чтобы  облегчить нам работу, мы переведем все в ASCII, сделаем lowercase и выкинем большинство пунктуации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ygu9l499kf96"
   },
   "outputs": [],
   "source": [
    "# \"hello!\" -> hello, ! \n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nExIwuorkf98"
   },
   "source": [
    "При чтении данных разделим файл на строки, а строки на пары.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kR6MaACekf99"
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "    \n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('happiness_provokers', encoding='utf-8')\n",
    "\n",
    "    # Get pairs and normalize\n",
    "    pairs = list(zip([normalizeString(s) for s in list(df['query'].values)], [normalizeString(s) for s in list(df.reply.values)]))\n",
    "    \n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAvHyswFrMj7",
    "outputId": "28b73ea3-9bbf-496a-b4cb-db94bf59ae5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 8.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 49.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 3.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.6 MB 41.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.6.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NMwAc5_8rPuY"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "5bf945ae3c7540f6ba472f20e2fdacb1",
      "7129a21f55af4ccb8bb7544ee34b6831",
      "ffe6cf8b83c649ec8aa08d270316b730",
      "c3382ae68dd84a4ba848cf70807658e0",
      "0db735ce391a424c87a3f287340ab7fa",
      "69de0ae6cbbe4eb7812e5884318d20b6",
      "6e6527f3e6c24c69ab4d669c28207a84",
      "5f0035855dfe4cd597ee7030acf16d72",
      "489ea138854d48008e1904c9e46dd6c1",
      "f2f168b45b1745a3ac7fb3c21699faa9",
      "37b45c0d2e3f421f8f8dba60722b1762",
      "1a279709b86e47e6b44117900e352dde",
      "f2392865fc8646509d45a5bfcdbdaad5",
      "9d1ff43c43ee4dfd9d3d6db33f3fef7f",
      "5bf2e4b9333d4909b661e69dc5e5bb5c",
      "061670ab7df04ec59ac89a79141d5773",
      "6a228332a0f44ba29f6e211f43c884a7",
      "9002278fd22143c69a6ab1dd360bcbcf",
      "0ad9f6135f4b4405b5facba733d28865",
      "1ecd56e5cd334e90ac1963e6255723b6",
      "fa1455eaad504e11b44f2a9ca79a6697",
      "63a6cde631a947a6bb85d1cbb89d9f21",
      "f60dee956d9d444f98a69ea9a6c8f17d",
      "2ea006d2693a46b7a6f73ad98c3ad71f",
      "5e76746f82b5427ab86238f4af8f0990",
      "efc568a8b8644795b1ac2e3e6a533a3c",
      "7fe87edbe4a945e3b48b4640aefc9aa0",
      "0f35c10168a74023b503c589e0a3e48e",
      "ed65250433ee4013acda7747b672123b",
      "a688e92efa5740e3ae9a4dc973a06df8",
      "fecd7f53f93644bfa8c70dc8946a7919",
      "df887e109e674daeb07ea2a6a9291202",
      "7740d64e27724da6ba665101cbe4fd74"
     ]
    },
    "id": "9D0dSudIra29",
    "outputId": "ea4ff828-33a6-417c-df78-aa39e7cf5854"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf945ae3c7540f6ba472f20e2fdacb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a279709b86e47e6b44117900e352dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60dee956d9d444f98a69ea9a6c8f17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dxwJGabVrl9Y"
   },
   "outputs": [],
   "source": [
    "seq = \"\"\"Hi bruh wtf r u doing ahh?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ld2s6T5IrpRY",
    "outputId": "b4df701d-72c0-4cc0-e314-d415a34f27ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      " bru\n",
      "h\n",
      " w\n",
      "tf\n",
      " r\n",
      " u\n",
      " doing\n",
      " a\n",
      "hh\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "for i in tokenizer.encode(seq):\n",
    "  print(tokenizer.decode(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSo1cu0rkf-C"
   },
   "source": [
    "Полный процесс такой:\n",
    "\n",
    "- Считать текстовый файл, просплитить по линиям, а затем по парам.\n",
    "- Нормализовать текст, профильтровать по длине.\n",
    "- Сделать готовые списки слов из сырых предложений в каждом языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "1G_BKtnukf-D",
    "outputId": "f3e4fd1e-3fdd-46c7-9ded-85397918896d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aa179c50576f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eng_user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eng_emotion_provoker'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-aa179c50576f>\u001b[0m in \u001b[0;36mprepareData\u001b[0;34m(lang1, lang2, reverse)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepareData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0minput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreadLangs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read %s sentence pairs\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Counting words...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d16e526542a3>\u001b[0m in \u001b[0;36mreadLangs\u001b[0;34m(lang1, lang2, reverse)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'happiness_provokers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Get pairs and normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'happiness_provokers'"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    pairs = pairs[::50]\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng_user', 'eng_emotion_provoker')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OM1rYFl6lRi3"
   },
   "outputs": [],
   "source": [
    "input_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GmEuofeTlPKw"
   },
   "outputs": [],
   "source": [
    "output_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dMte9MFpoBy"
   },
   "outputs": [],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBIv4CpwpoBy"
   },
   "outputs": [],
   "source": [
    "pairs[24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmijlK-akf-G"
   },
   "source": [
    "The Seq2Seq Model\n",
    "=================\n",
    "\n",
    "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
    "sequence and uses its own output as input for subsequent steps.\n",
    "\n",
    "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
    "seq2seq network, or `Encoder Decoder\n",
    "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
    "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
    "an input sequence and outputs a single vector, and the decoder reads\n",
    "that vector to produce an output sequence.\n",
    "\n",
    "\n",
    "Unlike sequence prediction with a single RNN, where every input\n",
    "corresponds to an output, the seq2seq model frees us from sequence\n",
    "length and order, which makes it ideal for translation between two\n",
    "languages.\n",
    "\n",
    "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
    "black cat\". Most of the words in the input sentence have a direct\n",
    "translation in the output sentence, but are in slightly different\n",
    "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
    "construction there is also one more word in the input sentence. It would\n",
    "be difficult to produce a correct translation directly from the sequence\n",
    "of input words.\n",
    "\n",
    "With a seq2seq model the encoder creates a single vector which, in the\n",
    "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
    "vector — a single point in some N dimensional space of sentences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzGBS-alkf-H"
   },
   "source": [
    "The Encoder\n",
    "-----------\n",
    "\n",
    "The encoder of a seq2seq network is a RNN that outputs some value for\n",
    "every word from the input sentence. For every input word the encoder\n",
    "outputs a vector and a hidden state, and uses the hidden state for the\n",
    "next input word.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtVkq0VQBhdx"
   },
   "source": [
    "(https://blog.floydhub.com/content/images/2019/07/image17-1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpcrvvXakf-I"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # num_embedding = vocab_size_fra\n",
    "        self.embedder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # (batch_size, num_words) -> (batch_size, num_words, dim_1)\n",
    "        embeddings = self.embedder(input).view(1, 1, -1)\n",
    "        # (batch_size, num_words, dim_2)\n",
    "        output, hidden = self.gru(embeddings, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-WEZjgj0poBz"
   },
   "outputs": [],
   "source": [
    "tokens = torch.randint(0, 1000, size=(128, 40))\n",
    "embedder = nn.Embedding(1000, 128)  # здесь лежит матрица"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-Ick8dBpoBz"
   },
   "outputs": [],
   "source": [
    "onehot = torch.nn.functional.one_hot(tokens, num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3kNebFKpoBz"
   },
   "outputs": [],
   "source": [
    "embeddingds_first_way = embedder(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-LYlliqEtLay"
   },
   "outputs": [],
   "source": [
    "embeddingds_first_way.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNZcay6Hkf-K"
   },
   "source": [
    "The Decoder\n",
    "-----------\n",
    "\n",
    "The decoder is another RNN that takes the encoder output vector(s) and\n",
    "outputs a sequence of words to create the translation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWJW6eKikf-L"
   },
   "source": [
    "Simple Decoder\n",
    "_________________\n",
    "\n",
    "In the simplest seq2seq decoder we use only last output of the encoder.\n",
    "This last output is sometimes called the *context vector* as it encodes\n",
    "context from the entire sequence. This context vector is used as the\n",
    "initial hidden state of the decoder.\n",
    "\n",
    "At every step of decoding, the decoder is given an input token and\n",
    "hidden state. The initial input token is the start-of-string ``<SOS>`` or `<BOS>`\n",
    "token, and the first hidden state is the context vector (the encoder's\n",
    "last hidden state).\n",
    "The last token is `<EOS>` whats mean end of string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtM1ZGRskf-M"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedder = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # (batch_size, num_words, dim)\n",
    "        # (1, 1, num_words * dim)\n",
    "        output = self.embedder(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        # (batch_size, num_words, dim) -> (batch_size, num_words, num_classes)\n",
    "        # (batch_size, num_words, vocab_size_eng)\n",
    "        output = self.out(output[0])\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfTzzPptkf-O"
   },
   "source": [
    "I encourage you to train and observe the results of this model, but to\n",
    "save space we'll be going straight for the gold and introducing the\n",
    "Attention Mechanism.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNllTJbIkf-P"
   },
   "source": [
    "Attention Decoder\n",
    "____________\n",
    "\n",
    "If only the context vector is passed betweeen the encoder and decoder,\n",
    "that single vector carries the burden of encoding the entire sentence.\n",
    "\n",
    "Attention allows the decoder network to \"focus\" on a different part of\n",
    "the encoder's outputs for every step of the decoder's own outputs. First\n",
    "we calculate a set of *attention weights*. These will be multiplied by\n",
    "the encoder output vectors to create a weighted combination. The result\n",
    "(called ``attn_applied`` in the code) should contain information about\n",
    "that specific part of the input sequence, and thus help the decoder\n",
    "choose the right output words.\n",
    "\n",
    "Calculating the attention weights is done with another feed-forward\n",
    "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
    "Because there are sentences of all sizes in the training data, to\n",
    "actually create and train this layer we have to choose a maximum\n",
    "sentence length (input length, for encoder outputs) that it can apply\n",
    "to. Sentences of the maximum length will use all the attention weights,\n",
    "while shorter sentences will only use the first few.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1sZQGIJpoB0"
   },
   "outputs": [],
   "source": [
    "# v^TWm\n",
    "# U^T tanh (W_1 v + W_2 m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZwO_Gg2kf-P"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(\n",
    "                torch.cat((embedded[0], hidden[0]), 1)\n",
    "            ), \n",
    "            dim=1\n",
    "        )\n",
    "        attn_applied = torch.bmm(\n",
    "            attn_weights.unsqueeze(0),\n",
    "            encoder_outputs.unsqueeze(0)\n",
    "        )\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLtuThIQkf-R"
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
    "  limitation by using a relative position approach. Read about \"local\n",
    "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
    "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
    "\n",
    "Training\n",
    "========\n",
    "\n",
    "Preparing Training Data\n",
    "-----------------------\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the\n",
    "words in the input sentence) and target tensor (indexes of the words in\n",
    "the target sentence). While creating these vectors we will append the\n",
    "EOS token to both sequences.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nmb8OwO7kf-S"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3OzldY0kf-U"
   },
   "source": [
    "Training the Model\n",
    "------------------\n",
    "\n",
    "To train we run the input sentence through the encoder, and keep track\n",
    "of every output and the latest hidden state. Then the decoder is given\n",
    "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
    "encoder as its first hidden state.\n",
    "\n",
    "\"Teacher forcing\" is the concept of using the real target outputs as\n",
    "each next input, instead of using the decoder's guess as the next input.\n",
    "Using teacher forcing causes it to converge faster but `when the trained\n",
    "network is exploited, it may exhibit\n",
    "instability <http://minds.jacobs-university.de/sites/default/files/uploads/papers/ESNTutorialRev.pdf>`__.\n",
    "\n",
    "You can observe outputs of teacher-forced networks that read with\n",
    "coherent grammar but wander far from the correct translation -\n",
    "intuitively it has learned to represent the output grammar and can \"pick\n",
    "up\" the meaning once the teacher tells it the first few words, but it\n",
    "has not properly learned how to create the sentence from the translation\n",
    "in the first place.\n",
    "\n",
    "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
    "choose to use teacher forcing or not with a simple if statement. Turn\n",
    "``teacher_forcing_ratio`` up to use more of it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "na-c3f0nkf-V"
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(\n",
    "    input_tensor, \n",
    "    target_tensor,\n",
    "    encoder, \n",
    "    decoder, \n",
    "    encoder_optimizer,\n",
    "    decoder_optimizer, \n",
    "    criterion,\n",
    "    max_length=MAX_LENGTH\n",
    "):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        # y_true: [sos, i, love, pizza, eos]\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # [0.9, 0.1, 0.0]\n",
    "            # [1, 0, 0]\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # beam_search is betters\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                # y_true: [sos, i, eos]\n",
    "                # [sos, i, eos, love]\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfmlhEzDkf-X"
   },
   "source": [
    "This is a helper function to print time elapsed and estimated time\n",
    "remaining given the current time and progress %.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNbWUTxfkf-Y"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wc8pY8ZCkf-a"
   },
   "source": [
    "The whole training process looks like this:\n",
    "\n",
    "-  Start a timer\n",
    "-  Initialize optimizers and criterion\n",
    "-  Create set of training pairs\n",
    "-  Start empty losses array for plotting\n",
    "\n",
    "Then we call ``train`` many times and occasionally print the progress (%\n",
    "of examples, time so far, estimated time) and average loss.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "skZhUHw1kf-a"
   },
   "outputs": [],
   "source": [
    "PATH_ENC = \"/content/drive/MyDrive/blablaenc.pt\"\n",
    "PATH_DECO = \"/content/drive/MyDrive/blabladeco.pt\"\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % 100 == 0:\n",
    "          torch.save(encoder.state_dict(), PATH_ENC)\n",
    "          torch.save(decoder.state_dict(), PATH_DECO)\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4JmR_fkf-d"
   },
   "source": [
    "Plotting results\n",
    "----------------\n",
    "\n",
    "Plotting is done with matplotlib, using the array of loss values\n",
    "``plot_losses`` saved while training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zf3Fhj-5kf-e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgHOJ5Ugkf-j"
   },
   "source": [
    "Evaluation\n",
    "==========\n",
    "\n",
    "Evaluation is mostly the same as training, but there are no targets so\n",
    "we simply feed the decoder's predictions back to itself for each step.\n",
    "Every time it predicts a word we add it to the output string, and if it\n",
    "predicts the EOS token we stop there. We also store the decoder's\n",
    "attention outputs for display later.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvYgjVG_kf-j"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-Xly1n3kf-l"
   },
   "source": [
    "We can evaluate random sentences from the training set and print out the\n",
    "input, target, and output to make some subjective quality judgements:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "58m1z4kJkf-m"
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrSEC280kf-o"
   },
   "source": [
    "Training and Evaluating\n",
    "=======================\n",
    "\n",
    "With all these helper functions in place (it looks like extra work, but\n",
    "it makes it easier to run multiple experiments) we can actually\n",
    "initialize a network and start training.\n",
    "\n",
    "Remember that the input sentences were heavily filtered. For this small\n",
    "dataset we can use relatively small networks of 256 hidden nodes and a\n",
    "single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
    "reasonable results.\n",
    "\n",
    ".. Note::\n",
    "   If you run this notebook you can train, interrupt the kernel,\n",
    "   evaluate, and continue training later. Comment out the lines where the\n",
    "   encoder and decoder are initialized and run ``trainIters`` again.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FUhy164sqRzG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uBS0Q3gokf-p",
    "outputId": "8851f1df-8bc3-4052-b25f-4aa9d8e07a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 14s (- 355m 29s) (50 0%) 3.0470\n",
      "0m 18s (- 229m 44s) (100 0%) 3.4556\n",
      "0m 21s (- 182m 11s) (150 0%) 3.0071\n",
      "0m 25s (- 159m 22s) (200 0%) 3.1157\n",
      "0m 29s (- 145m 18s) (250 0%) 2.8717\n",
      "0m 33s (- 140m 0s) (300 0%) 3.0032\n",
      "0m 37s (- 132m 44s) (350 0%) 3.0989\n",
      "0m 41s (- 129m 29s) (400 0%) 2.9812\n",
      "0m 45s (- 125m 59s) (450 0%) 2.7581\n",
      "0m 50s (- 124m 33s) (500 0%) 3.0217\n",
      "0m 53s (- 121m 3s) (550 0%) 3.0000\n",
      "0m 57s (- 119m 36s) (600 0%) 2.8369\n",
      "1m 3s (- 120m 44s) (650 0%) 2.7795\n",
      "1m 7s (- 119m 34s) (700 0%) 2.8778\n",
      "1m 11s (- 117m 14s) (750 1%) 2.9129\n",
      "1m 14s (- 115m 44s) (800 1%) 2.8407\n",
      "1m 18s (- 114m 39s) (850 1%) 2.8018\n",
      "1m 22s (- 113m 14s) (900 1%) 2.3785\n",
      "1m 26s (- 112m 20s) (950 1%) 2.8117\n",
      "1m 30s (- 111m 17s) (1000 1%) 2.7018\n",
      "1m 33s (- 110m 12s) (1050 1%) 2.6431\n",
      "1m 37s (- 109m 27s) (1100 1%) 3.2999\n",
      "1m 41s (- 108m 54s) (1150 1%) 2.7431\n",
      "1m 46s (- 108m 39s) (1200 1%) 3.0473\n",
      "1m 49s (- 108m 3s) (1250 1%) 2.6619\n",
      "1m 53s (- 107m 39s) (1300 1%) 2.9126\n",
      "1m 57s (- 107m 1s) (1350 1%) 2.6656\n",
      "2m 1s (- 106m 19s) (1400 1%) 2.9118\n",
      "2m 4s (- 105m 39s) (1450 1%) 2.4926\n",
      "2m 9s (- 105m 31s) (1500 2%) 2.7965\n",
      "2m 12s (- 104m 58s) (1550 2%) 2.4656\n",
      "2m 16s (- 104m 30s) (1600 2%) 2.8466\n",
      "2m 20s (- 104m 10s) (1650 2%) 2.6614\n",
      "2m 24s (- 103m 47s) (1700 2%) 3.0170\n",
      "2m 28s (- 103m 29s) (1750 2%) 2.7917\n",
      "2m 32s (- 103m 10s) (1800 2%) 3.0216\n",
      "2m 35s (- 102m 47s) (1850 2%) 2.5322\n",
      "2m 39s (- 102m 22s) (1900 2%) 2.4641\n",
      "2m 43s (- 102m 7s) (1950 2%) 2.8214\n",
      "2m 47s (- 102m 6s) (2000 2%) 2.8746\n",
      "2m 51s (- 101m 56s) (2050 2%) 2.1533\n",
      "2m 55s (- 101m 42s) (2100 2%) 2.5139\n",
      "2m 59s (- 101m 28s) (2150 2%) 2.7182\n",
      "3m 3s (- 101m 23s) (2200 2%) 2.6393\n",
      "3m 7s (- 101m 5s) (2250 3%) 2.3265\n",
      "3m 11s (- 101m 2s) (2300 3%) 2.8197\n",
      "3m 15s (- 100m 53s) (2350 3%) 2.6970\n",
      "3m 19s (- 100m 41s) (2400 3%) 2.4080\n",
      "3m 23s (- 100m 38s) (2450 3%) 2.1561\n",
      "3m 28s (- 100m 39s) (2500 3%) 2.8096\n",
      "3m 32s (- 100m 33s) (2550 3%) 2.5234\n",
      "3m 36s (- 100m 31s) (2600 3%) 2.8984\n",
      "3m 40s (- 100m 16s) (2650 3%) 2.2340\n",
      "3m 45s (- 100m 25s) (2700 3%) 2.8730\n",
      "3m 49s (- 100m 19s) (2750 3%) 2.3371\n",
      "3m 53s (- 100m 23s) (2800 3%) 2.1668\n",
      "3m 57s (- 100m 17s) (2850 3%) 2.5035\n",
      "4m 1s (- 100m 4s) (2900 3%) 2.3026\n",
      "4m 5s (- 99m 57s) (2950 3%) 2.4813\n",
      "4m 9s (- 99m 51s) (3000 4%) 2.6304\n",
      "4m 13s (- 99m 39s) (3050 4%) 2.3326\n",
      "4m 17s (- 99m 30s) (3100 4%) 1.9303\n",
      "4m 21s (- 99m 29s) (3150 4%) 2.5821\n",
      "4m 25s (- 99m 21s) (3200 4%) 2.4333\n",
      "4m 29s (- 99m 9s) (3250 4%) 2.1033\n",
      "4m 33s (- 99m 8s) (3300 4%) 2.0014\n",
      "4m 37s (- 98m 55s) (3350 4%) 2.2921\n",
      "4m 41s (- 98m 49s) (3400 4%) 2.0487\n",
      "4m 45s (- 98m 43s) (3450 4%) 2.4809\n",
      "4m 49s (- 98m 43s) (3500 4%) 2.2993\n",
      "4m 53s (- 98m 35s) (3550 4%) 2.0047\n",
      "4m 58s (- 98m 31s) (3600 4%) 2.3576\n",
      "5m 1s (- 98m 22s) (3650 4%) 2.4695\n",
      "5m 5s (- 98m 15s) (3700 4%) 2.2073\n",
      "5m 9s (- 98m 9s) (3750 5%) 2.0435\n",
      "5m 13s (- 97m 55s) (3800 5%) 1.7976\n",
      "5m 17s (- 97m 50s) (3850 5%) 2.3896\n",
      "5m 21s (- 97m 44s) (3900 5%) 2.7457\n",
      "5m 25s (- 97m 35s) (3950 5%) 2.3540\n",
      "5m 29s (- 97m 25s) (4000 5%) 2.1765\n",
      "5m 33s (- 97m 21s) (4050 5%) 2.3244\n",
      "5m 37s (- 97m 17s) (4100 5%) 2.2627\n",
      "5m 41s (- 97m 9s) (4150 5%) 1.8975\n",
      "5m 45s (- 97m 4s) (4200 5%) 2.4137\n",
      "5m 49s (- 97m 3s) (4250 5%) 2.4703\n",
      "5m 53s (- 96m 57s) (4300 5%) 2.3449\n",
      "5m 57s (- 96m 49s) (4350 5%) 2.3563\n",
      "6m 2s (- 96m 48s) (4400 5%) 2.1016\n",
      "6m 5s (- 96m 38s) (4450 5%) 2.2481\n",
      "6m 10s (- 96m 39s) (4500 6%) 2.2799\n",
      "6m 14s (- 96m 32s) (4550 6%) 2.6421\n",
      "6m 17s (- 96m 23s) (4600 6%) 2.3799\n",
      "6m 22s (- 96m 22s) (4650 6%) 1.9747\n",
      "6m 26s (- 96m 17s) (4700 6%) 2.1417\n",
      "6m 29s (- 96m 5s) (4750 6%) 1.9717\n",
      "6m 33s (- 95m 58s) (4800 6%) 2.2466\n",
      "6m 37s (- 95m 52s) (4850 6%) 2.0905\n",
      "6m 41s (- 95m 49s) (4900 6%) 2.1798\n",
      "6m 45s (- 95m 39s) (4950 6%) 2.1997\n",
      "6m 50s (- 95m 41s) (5000 6%) 2.0669\n",
      "6m 54s (- 95m 35s) (5050 6%) 2.2367\n",
      "6m 57s (- 95m 25s) (5100 6%) 2.0045\n",
      "7m 1s (- 95m 19s) (5150 6%) 1.9234\n",
      "7m 5s (- 95m 13s) (5200 6%) 2.0983\n",
      "7m 9s (- 95m 5s) (5250 7%) 2.2207\n",
      "7m 13s (- 95m 3s) (5300 7%) 2.0286\n",
      "7m 17s (- 94m 52s) (5350 7%) 1.8708\n",
      "7m 21s (- 94m 47s) (5400 7%) 2.2158\n",
      "7m 25s (- 94m 40s) (5450 7%) 2.3310\n",
      "7m 29s (- 94m 35s) (5500 7%) 1.8680\n",
      "7m 32s (- 94m 27s) (5550 7%) 1.7128\n",
      "7m 36s (- 94m 18s) (5600 7%) 1.8647\n",
      "7m 40s (- 94m 10s) (5650 7%) 2.0161\n",
      "7m 44s (- 94m 7s) (5700 7%) 1.7979\n",
      "7m 48s (- 94m 6s) (5750 7%) 1.8876\n",
      "7m 53s (- 94m 4s) (5800 7%) 2.2627\n",
      "7m 57s (- 93m 59s) (5850 7%) 1.8217\n",
      "8m 1s (- 93m 55s) (5900 7%) 2.0690\n",
      "8m 5s (- 93m 54s) (5950 7%) 2.2980\n",
      "8m 9s (- 93m 51s) (6000 8%) 1.9033\n",
      "8m 13s (- 93m 42s) (6050 8%) 1.9972\n",
      "8m 17s (- 93m 42s) (6100 8%) 2.2663\n",
      "8m 21s (- 93m 34s) (6150 8%) 1.8363\n",
      "8m 25s (- 93m 33s) (6200 8%) 2.0630\n",
      "8m 29s (- 93m 28s) (6250 8%) 2.0791\n",
      "8m 33s (- 93m 23s) (6300 8%) 1.5354\n",
      "8m 37s (- 93m 16s) (6350 8%) 1.8642\n",
      "8m 41s (- 93m 13s) (6400 8%) 2.1717\n",
      "8m 45s (- 93m 8s) (6450 8%) 2.1371\n",
      "8m 49s (- 93m 4s) (6500 8%) 2.0127\n",
      "8m 53s (- 92m 56s) (6550 8%) 1.7433\n",
      "8m 57s (- 92m 50s) (6600 8%) 2.3726\n",
      "9m 1s (- 92m 46s) (6650 8%) 2.3358\n",
      "9m 6s (- 92m 48s) (6700 8%) 1.9745\n",
      "9m 10s (- 92m 43s) (6750 9%) 2.0549\n",
      "9m 14s (- 92m 37s) (6800 9%) 1.9417\n",
      "9m 17s (- 92m 28s) (6850 9%) 2.2031\n",
      "9m 21s (- 92m 23s) (6900 9%) 1.6499\n",
      "9m 25s (- 92m 15s) (6950 9%) 1.8082\n",
      "9m 29s (- 92m 7s) (7000 9%) 1.7433\n",
      "9m 32s (- 92m 1s) (7050 9%) 1.8770\n",
      "9m 36s (- 91m 55s) (7100 9%) 1.5408\n",
      "9m 40s (- 91m 50s) (7150 9%) 1.9336\n",
      "9m 44s (- 91m 42s) (7200 9%) 1.4564\n",
      "9m 48s (- 91m 34s) (7250 9%) 1.8875\n",
      "9m 51s (- 91m 28s) (7300 9%) 1.6372\n",
      "9m 55s (- 91m 22s) (7350 9%) 1.8831\n",
      "9m 59s (- 91m 20s) (7400 9%) 2.0983\n",
      "10m 3s (- 91m 12s) (7450 9%) 1.9543\n",
      "10m 7s (- 91m 9s) (7500 10%) 1.6971\n",
      "10m 11s (- 91m 6s) (7550 10%) 1.8233\n",
      "10m 16s (- 91m 3s) (7600 10%) 1.8283\n",
      "10m 19s (- 90m 57s) (7650 10%) 1.7843\n",
      "10m 23s (- 90m 52s) (7700 10%) 1.7427\n",
      "10m 28s (- 90m 50s) (7750 10%) 1.9414\n",
      "10m 32s (- 90m 45s) (7800 10%) 1.6015\n",
      "10m 35s (- 90m 37s) (7850 10%) 1.8544\n",
      "10m 39s (- 90m 35s) (7900 10%) 1.8971\n",
      "10m 44s (- 90m 32s) (7950 10%) 2.0863\n",
      "10m 48s (- 90m 29s) (8000 10%) 1.9301\n",
      "10m 52s (- 90m 25s) (8050 10%) 2.0334\n",
      "10m 56s (- 90m 24s) (8100 10%) 1.6595\n",
      "11m 0s (- 90m 20s) (8150 10%) 1.9384\n",
      "11m 4s (- 90m 17s) (8200 10%) 1.7405\n",
      "11m 9s (- 90m 13s) (8250 11%) 1.8315\n",
      "11m 13s (- 90m 11s) (8300 11%) 2.0832\n",
      "11m 17s (- 90m 4s) (8350 11%) 1.8968\n",
      "11m 21s (- 90m 3s) (8400 11%) 2.0538\n",
      "11m 25s (- 89m 57s) (8450 11%) 2.1259\n",
      "11m 29s (- 89m 50s) (8500 11%) 1.4400\n",
      "11m 32s (- 89m 44s) (8550 11%) 2.0372\n",
      "11m 36s (- 89m 39s) (8600 11%) 1.6568\n",
      "11m 40s (- 89m 33s) (8650 11%) 1.5285\n",
      "11m 44s (- 89m 29s) (8700 11%) 1.3905\n",
      "11m 48s (- 89m 24s) (8750 11%) 1.6040\n",
      "11m 52s (- 89m 20s) (8800 11%) 2.1349\n",
      "11m 56s (- 89m 16s) (8850 11%) 1.5914\n",
      "12m 0s (- 89m 13s) (8900 11%) 1.6599\n",
      "12m 4s (- 89m 6s) (8950 11%) 1.5249\n",
      "12m 8s (- 89m 2s) (9000 12%) 1.7888\n",
      "12m 12s (- 88m 59s) (9050 12%) 1.7773\n",
      "12m 16s (- 88m 56s) (9100 12%) 1.9870\n",
      "12m 20s (- 88m 51s) (9150 12%) 1.6434\n",
      "12m 24s (- 88m 47s) (9200 12%) 1.8900\n",
      "12m 28s (- 88m 43s) (9250 12%) 2.0464\n",
      "12m 32s (- 88m 37s) (9300 12%) 1.5029\n",
      "12m 36s (- 88m 30s) (9350 12%) 1.7867\n",
      "12m 40s (- 88m 25s) (9400 12%) 1.4804\n",
      "12m 44s (- 88m 21s) (9450 12%) 1.5808\n",
      "12m 48s (- 88m 18s) (9500 12%) 1.8800\n",
      "12m 52s (- 88m 14s) (9550 12%) 2.0144\n",
      "12m 56s (- 88m 11s) (9600 12%) 1.5999\n",
      "13m 0s (- 88m 7s) (9650 12%) 1.4754\n",
      "13m 4s (- 88m 3s) (9700 12%) 1.6258\n",
      "13m 8s (- 87m 59s) (9750 13%) 2.0605\n",
      "13m 12s (- 87m 54s) (9800 13%) 1.6425\n",
      "13m 16s (- 87m 48s) (9850 13%) 1.7831\n",
      "13m 20s (- 87m 41s) (9900 13%) 1.5150\n",
      "13m 24s (- 87m 36s) (9950 13%) 1.4811\n",
      "13m 28s (- 87m 32s) (10000 13%) 1.6469\n",
      "13m 31s (- 87m 27s) (10050 13%) 1.7486\n",
      "13m 36s (- 87m 25s) (10100 13%) 2.0994\n",
      "13m 40s (- 87m 22s) (10150 13%) 2.1145\n",
      "13m 44s (- 87m 18s) (10200 13%) 1.8055\n",
      "13m 48s (- 87m 13s) (10250 13%) 1.7904\n",
      "13m 52s (- 87m 9s) (10300 13%) 2.2180\n",
      "13m 56s (- 87m 3s) (10350 13%) 1.7549\n",
      "14m 0s (- 86m 59s) (10400 13%) 1.7232\n",
      "14m 4s (- 86m 55s) (10450 13%) 1.3217\n",
      "14m 8s (- 86m 50s) (10500 14%) 1.7716\n",
      "14m 12s (- 86m 44s) (10550 14%) 1.6173\n",
      "14m 15s (- 86m 40s) (10600 14%) 1.4200\n",
      "14m 20s (- 86m 36s) (10650 14%) 1.6347\n",
      "14m 23s (- 86m 31s) (10700 14%) 1.7350\n",
      "14m 27s (- 86m 27s) (10750 14%) 1.7481\n",
      "14m 32s (- 86m 26s) (10800 14%) 1.7019\n",
      "14m 36s (- 86m 21s) (10850 14%) 1.4947\n",
      "14m 40s (- 86m 16s) (10900 14%) 1.6444\n",
      "14m 44s (- 86m 13s) (10950 14%) 1.9013\n",
      "14m 48s (- 86m 10s) (11000 14%) 1.6609\n",
      "14m 52s (- 86m 6s) (11050 14%) 1.6841\n",
      "14m 57s (- 86m 3s) (11100 14%) 1.5336\n",
      "15m 0s (- 85m 59s) (11150 14%) 1.9201\n",
      "15m 4s (- 85m 54s) (11200 14%) 1.5345\n",
      "15m 8s (- 85m 49s) (11250 15%) 1.4632\n",
      "15m 12s (- 85m 45s) (11300 15%) 1.8449\n",
      "15m 16s (- 85m 41s) (11350 15%) 1.2564\n",
      "15m 20s (- 85m 37s) (11400 15%) 1.4741\n",
      "15m 24s (- 85m 32s) (11450 15%) 1.2047\n",
      "15m 29s (- 85m 29s) (11500 15%) 2.1181\n",
      "15m 32s (- 85m 24s) (11550 15%) 1.6755\n",
      "15m 36s (- 85m 20s) (11600 15%) 1.5930\n",
      "15m 40s (- 85m 16s) (11650 15%) 1.9765\n",
      "15m 44s (- 85m 10s) (11700 15%) 1.3080\n",
      "15m 48s (- 85m 6s) (11750 15%) 1.9539\n",
      "15m 52s (- 85m 1s) (11800 15%) 1.7328\n",
      "15m 56s (- 84m 57s) (11850 15%) 1.8287\n",
      "16m 0s (- 84m 52s) (11900 15%) 2.0678\n",
      "16m 4s (- 84m 47s) (11950 15%) 1.8740\n",
      "16m 8s (- 84m 42s) (12000 16%) 1.6434\n",
      "16m 11s (- 84m 36s) (12050 16%) 1.8677\n",
      "16m 15s (- 84m 33s) (12100 16%) 1.9644\n",
      "16m 20s (- 84m 30s) (12150 16%) 2.0994\n",
      "16m 24s (- 84m 26s) (12200 16%) 2.0660\n",
      "16m 28s (- 84m 22s) (12250 16%) 1.5395\n",
      "16m 32s (- 84m 19s) (12300 16%) 1.8115\n",
      "16m 36s (- 84m 16s) (12350 16%) 1.6287\n",
      "16m 40s (- 84m 12s) (12400 16%) 1.7272\n",
      "16m 45s (- 84m 9s) (12450 16%) 1.9139\n",
      "16m 49s (- 84m 5s) (12500 16%) 1.7691\n",
      "16m 52s (- 84m 0s) (12550 16%) 1.6276\n",
      "16m 57s (- 83m 56s) (12600 16%) 1.8655\n",
      "17m 0s (- 83m 52s) (12650 16%) 2.0366\n",
      "17m 4s (- 83m 47s) (12700 16%) 1.9422\n",
      "17m 8s (- 83m 43s) (12750 17%) 1.6905\n",
      "17m 13s (- 83m 40s) (12800 17%) 1.7038\n",
      "17m 16s (- 83m 34s) (12850 17%) 1.5387\n",
      "17m 21s (- 83m 31s) (12900 17%) 1.4899\n",
      "17m 25s (- 83m 28s) (12950 17%) 1.8875\n",
      "17m 29s (- 83m 23s) (13000 17%) 1.3844\n",
      "17m 33s (- 83m 19s) (13050 17%) 1.6729\n",
      "17m 37s (- 83m 14s) (13100 17%) 1.5140\n",
      "17m 40s (- 83m 9s) (13150 17%) 1.3950\n",
      "17m 45s (- 83m 7s) (13200 17%) 1.4929\n",
      "17m 49s (- 83m 4s) (13250 17%) 1.9871\n",
      "17m 53s (- 83m 1s) (13300 17%) 1.6684\n",
      "17m 58s (- 82m 59s) (13350 17%) 1.9415\n",
      "18m 2s (- 82m 56s) (13400 17%) 1.7897\n",
      "18m 6s (- 82m 51s) (13450 17%) 1.6649\n",
      "18m 10s (- 82m 49s) (13500 18%) 1.7108\n",
      "18m 14s (- 82m 45s) (13550 18%) 1.8834\n",
      "18m 19s (- 82m 42s) (13600 18%) 1.8609\n",
      "18m 23s (- 82m 37s) (13650 18%) 1.5069\n",
      "18m 27s (- 82m 33s) (13700 18%) 1.9018\n",
      "18m 31s (- 82m 29s) (13750 18%) 1.6632\n",
      "18m 35s (- 82m 25s) (13800 18%) 1.5239\n",
      "18m 39s (- 82m 22s) (13850 18%) 1.7068\n",
      "18m 43s (- 82m 19s) (13900 18%) 1.8083\n",
      "18m 48s (- 82m 16s) (13950 18%) 1.9059\n",
      "18m 51s (- 82m 12s) (14000 18%) 1.6497\n",
      "18m 56s (- 82m 9s) (14050 18%) 2.0094\n",
      "19m 0s (- 82m 6s) (14100 18%) 1.4525\n",
      "19m 4s (- 82m 2s) (14150 18%) 1.8166\n",
      "19m 8s (- 81m 58s) (14200 18%) 1.6943\n",
      "19m 12s (- 81m 54s) (14250 19%) 1.9159\n",
      "19m 17s (- 81m 51s) (14300 19%) 1.3998\n",
      "19m 21s (- 81m 48s) (14350 19%) 1.8516\n",
      "19m 25s (- 81m 46s) (14400 19%) 1.8127\n",
      "19m 30s (- 81m 43s) (14450 19%) 2.0241\n",
      "19m 34s (- 81m 41s) (14500 19%) 1.5871\n",
      "19m 38s (- 81m 36s) (14550 19%) 1.5742\n",
      "19m 42s (- 81m 33s) (14600 19%) 1.5864\n",
      "19m 47s (- 81m 30s) (14650 19%) 1.5321\n",
      "19m 51s (- 81m 26s) (14700 19%) 1.7131\n",
      "19m 55s (- 81m 23s) (14750 19%) 1.9135\n",
      "20m 0s (- 81m 22s) (14800 19%) 1.6347\n",
      "20m 4s (- 81m 18s) (14850 19%) 1.6855\n",
      "20m 8s (- 81m 15s) (14900 19%) 1.6040\n",
      "20m 12s (- 81m 10s) (14950 19%) 1.9405\n",
      "20m 17s (- 81m 8s) (15000 20%) 1.5004\n",
      "20m 21s (- 81m 7s) (15050 20%) 1.6059\n",
      "20m 26s (- 81m 4s) (15100 20%) 1.7961\n",
      "20m 30s (- 81m 1s) (15150 20%) 1.7281\n",
      "20m 34s (- 80m 57s) (15200 20%) 1.3522\n",
      "20m 39s (- 80m 54s) (15250 20%) 1.9171\n",
      "20m 43s (- 80m 51s) (15300 20%) 1.3839\n",
      "20m 47s (- 80m 48s) (15350 20%) 1.3134\n",
      "20m 51s (- 80m 45s) (15400 20%) 1.7502\n",
      "20m 55s (- 80m 40s) (15450 20%) 1.5006\n",
      "21m 0s (- 80m 37s) (15500 20%) 1.5139\n",
      "21m 4s (- 80m 33s) (15550 20%) 1.6040\n",
      "21m 8s (- 80m 29s) (15600 20%) 1.2324\n",
      "21m 12s (- 80m 26s) (15650 20%) 1.4330\n",
      "21m 16s (- 80m 22s) (15700 20%) 1.4430\n",
      "21m 20s (- 80m 18s) (15750 21%) 1.3859\n",
      "21m 24s (- 80m 14s) (15800 21%) 1.5576\n",
      "21m 28s (- 80m 9s) (15850 21%) 1.4491\n",
      "21m 32s (- 80m 4s) (15900 21%) 2.0318\n",
      "21m 36s (- 79m 59s) (15950 21%) 1.4105\n",
      "21m 40s (- 79m 56s) (16000 21%) 1.5978\n",
      "21m 44s (- 79m 51s) (16050 21%) 1.6051\n",
      "21m 48s (- 79m 47s) (16100 21%) 0.9983\n",
      "21m 52s (- 79m 43s) (16150 21%) 1.6949\n",
      "21m 56s (- 79m 38s) (16200 21%) 1.3822\n",
      "22m 0s (- 79m 34s) (16250 21%) 1.5879\n",
      "22m 4s (- 79m 31s) (16300 21%) 1.8557\n",
      "22m 9s (- 79m 30s) (16350 21%) 1.7592\n",
      "22m 13s (- 79m 26s) (16400 21%) 1.4981\n",
      "22m 18s (- 79m 22s) (16450 21%) 1.4099\n",
      "22m 22s (- 79m 19s) (16500 22%) 1.2288\n",
      "22m 26s (- 79m 14s) (16550 22%) 1.3222\n",
      "22m 30s (- 79m 11s) (16600 22%) 1.6905\n",
      "22m 34s (- 79m 5s) (16650 22%) 1.4110\n",
      "22m 38s (- 79m 2s) (16700 22%) 1.7130\n",
      "22m 42s (- 78m 58s) (16750 22%) 1.7474\n",
      "22m 46s (- 78m 54s) (16800 22%) 1.4866\n",
      "22m 50s (- 78m 49s) (16850 22%) 1.7087\n",
      "22m 54s (- 78m 45s) (16900 22%) 1.5877\n",
      "22m 58s (- 78m 42s) (16950 22%) 2.0013\n",
      "23m 2s (- 78m 38s) (17000 22%) 1.7293\n",
      "23m 6s (- 78m 32s) (17050 22%) 1.3893\n",
      "23m 10s (- 78m 29s) (17100 22%) 1.7952\n",
      "23m 14s (- 78m 25s) (17150 22%) 1.8316\n",
      "23m 19s (- 78m 21s) (17200 22%) 1.6997\n",
      "23m 22s (- 78m 16s) (17250 23%) 1.8038\n",
      "23m 27s (- 78m 12s) (17300 23%) 1.6363\n",
      "23m 30s (- 78m 7s) (17350 23%) 1.4765\n",
      "23m 34s (- 78m 3s) (17400 23%) 1.9356\n",
      "23m 38s (- 77m 58s) (17450 23%) 1.1320\n",
      "23m 43s (- 77m 56s) (17500 23%) 1.5982\n",
      "23m 47s (- 77m 52s) (17550 23%) 1.5844\n",
      "23m 51s (- 77m 48s) (17600 23%) 1.4486\n",
      "23m 55s (- 77m 42s) (17650 23%) 1.4274\n",
      "23m 59s (- 77m 39s) (17700 23%) 1.3797\n",
      "24m 3s (- 77m 34s) (17750 23%) 1.3891\n",
      "24m 6s (- 77m 29s) (17800 23%) 1.4357\n",
      "24m 11s (- 77m 26s) (17850 23%) 1.6985\n",
      "24m 15s (- 77m 22s) (17900 23%) 1.5563\n",
      "24m 19s (- 77m 17s) (17950 23%) 1.2162\n",
      "24m 23s (- 77m 14s) (18000 24%) 1.4698\n",
      "24m 27s (- 77m 9s) (18050 24%) 1.4746\n",
      "24m 31s (- 77m 5s) (18100 24%) 1.2835\n",
      "24m 35s (- 77m 1s) (18150 24%) 1.6213\n",
      "24m 39s (- 76m 57s) (18200 24%) 1.6183\n",
      "24m 43s (- 76m 53s) (18250 24%) 1.6322\n",
      "24m 47s (- 76m 48s) (18300 24%) 1.2847\n",
      "24m 51s (- 76m 43s) (18350 24%) 1.6750\n",
      "24m 55s (- 76m 38s) (18400 24%) 1.4738\n",
      "24m 58s (- 76m 33s) (18450 24%) 1.3127\n",
      "25m 2s (- 76m 29s) (18500 24%) 1.3100\n",
      "25m 6s (- 76m 24s) (18550 24%) 1.6177\n",
      "25m 10s (- 76m 20s) (18600 24%) 1.5064\n",
      "25m 14s (- 76m 17s) (18650 24%) 1.5793\n",
      "25m 19s (- 76m 13s) (18700 24%) 1.9733\n",
      "25m 23s (- 76m 9s) (18750 25%) 1.1177\n",
      "25m 26s (- 76m 4s) (18800 25%) 1.3348\n",
      "25m 30s (- 76m 0s) (18850 25%) 1.6759\n",
      "25m 34s (- 75m 56s) (18900 25%) 1.5509\n",
      "25m 38s (- 75m 50s) (18950 25%) 1.4010\n",
      "25m 42s (- 75m 46s) (19000 25%) 1.8038\n",
      "25m 46s (- 75m 41s) (19050 25%) 1.7764\n",
      "25m 51s (- 75m 39s) (19100 25%) 1.8891\n",
      "25m 54s (- 75m 34s) (19150 25%) 1.6630\n",
      "25m 58s (- 75m 30s) (19200 25%) 1.7152\n",
      "26m 3s (- 75m 26s) (19250 25%) 1.7801\n",
      "26m 7s (- 75m 22s) (19300 25%) 1.2940\n",
      "26m 11s (- 75m 18s) (19350 25%) 1.6842\n",
      "26m 15s (- 75m 15s) (19400 25%) 1.7524\n",
      "26m 19s (- 75m 11s) (19450 25%) 1.5136\n",
      "26m 23s (- 75m 7s) (19500 26%) 1.7417\n",
      "26m 28s (- 75m 4s) (19550 26%) 1.4709\n",
      "26m 32s (- 75m 0s) (19600 26%) 1.4185\n",
      "26m 36s (- 74m 56s) (19650 26%) 1.6954\n",
      "26m 40s (- 74m 52s) (19700 26%) 1.6477\n",
      "26m 44s (- 74m 47s) (19750 26%) 1.5858\n",
      "26m 48s (- 74m 43s) (19800 26%) 1.5002\n",
      "26m 52s (- 74m 39s) (19850 26%) 1.6434\n",
      "26m 56s (- 74m 35s) (19900 26%) 1.3911\n",
      "27m 0s (- 74m 30s) (19950 26%) 1.7338\n",
      "27m 4s (- 74m 26s) (20000 26%) 1.1979\n",
      "27m 8s (- 74m 21s) (20050 26%) 1.6293\n",
      "27m 11s (- 74m 17s) (20100 26%) 1.5543\n",
      "27m 15s (- 74m 12s) (20150 26%) 1.6820\n",
      "27m 19s (- 74m 8s) (20200 26%) 1.7846\n",
      "27m 23s (- 74m 3s) (20250 27%) 1.4209\n",
      "27m 27s (- 73m 58s) (20300 27%) 1.0785\n",
      "27m 31s (- 73m 55s) (20350 27%) 1.5530\n",
      "27m 35s (- 73m 51s) (20400 27%) 1.4975\n",
      "27m 40s (- 73m 48s) (20450 27%) 1.8590\n",
      "27m 44s (- 73m 44s) (20500 27%) 1.6645\n",
      "27m 48s (- 73m 39s) (20550 27%) 1.6271\n",
      "27m 51s (- 73m 35s) (20600 27%) 1.8418\n",
      "27m 55s (- 73m 30s) (20650 27%) 1.4497\n",
      "28m 0s (- 73m 27s) (20700 27%) 1.5884\n",
      "28m 4s (- 73m 22s) (20750 27%) 1.7880\n",
      "28m 8s (- 73m 18s) (20800 27%) 1.6481\n",
      "28m 11s (- 73m 13s) (20850 27%) 1.3138\n",
      "28m 15s (- 73m 9s) (20900 27%) 1.5024\n",
      "28m 20s (- 73m 6s) (20950 27%) 1.5314\n",
      "28m 24s (- 73m 3s) (21000 28%) 1.6358\n",
      "28m 28s (- 72m 58s) (21050 28%) 1.3754\n",
      "28m 32s (- 72m 54s) (21100 28%) 1.5450\n",
      "28m 35s (- 72m 48s) (21150 28%) 1.4361\n",
      "28m 39s (- 72m 44s) (21200 28%) 1.4822\n",
      "28m 43s (- 72m 39s) (21250 28%) 1.6993\n",
      "28m 47s (- 72m 36s) (21300 28%) 1.5452\n",
      "28m 52s (- 72m 33s) (21350 28%) 1.6421\n",
      "28m 56s (- 72m 29s) (21400 28%) 1.4338\n",
      "29m 0s (- 72m 25s) (21450 28%) 1.5256\n",
      "29m 4s (- 72m 21s) (21500 28%) 1.5228\n",
      "29m 8s (- 72m 17s) (21550 28%) 1.6108\n",
      "29m 12s (- 72m 13s) (21600 28%) 1.5973\n",
      "29m 16s (- 72m 9s) (21650 28%) 1.9892\n",
      "29m 21s (- 72m 5s) (21700 28%) 1.4813\n",
      "29m 24s (- 72m 0s) (21750 28%) 1.4107\n",
      "29m 28s (- 71m 56s) (21800 29%) 1.5977\n",
      "29m 32s (- 71m 52s) (21850 29%) 1.7547\n",
      "29m 36s (- 71m 48s) (21900 29%) 1.6278\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder1.load_state_dict(torch.load('/content/drive/MyDrive/D.pt')) # можно и другую директорию, но вот это прямо внутри вашего гугл диска\n",
    "attn_decoder1.load_state_dict(torch.load('/content/drive/MyDrive/G.pt'))\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_wUdnU1kf-s",
    "outputId": "b26cb3f8-a345-4bf7-93cb-dd6da9204a69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> wow amazon sure took advantage of that opportunity its crazy how much wharehouse workers have to walk though\n",
      "= yeah i same some articles about that . . . .they have to walk several football fields and by the time they get back their breaks are over .\n",
      "< yeah i same some articles about that . . . have to walk several football fields and by the time they get back their breaks are over . <EOS>\n",
      "\n",
      "> maybe so ! it would be a huge help wouldn t it ? you know i honestly can t believe the fda once burned six tons of literature . what a waste !\n",
      "= heartbreaking ! hey did you hear about sacramento s new library of things ?\n",
      "< oh ! ! ! ! ! ! have an insane budget for a comedy ! probably cost a lot of to have to and to ! <EOS>\n",
      "\n",
      "> you have to try new thing and not be afraid to admit your mistakes . comedy central would have been bankrupt if they continued to produce those unfunny shows .\n",
      "= true i learned this the other day . .the creator of the python programming language named it partly to honor british comedy group monty python\n",
      "< i agree . it in the the . <EOS>\n",
      "\n",
      "> oh yeah ! i can see that now ! so the cadillac was named after a french explorer antoine de la mothe cadillac .\n",
      "= that is interesting i always thought it was named after someone who invented the car .\n",
      "< that is interesting i i it that that was and that of was . of was . <EOS>\n",
      "\n",
      "> yes but if they are professional i think the ballet company pays for the shoes . do you prefer functional shoes or decorative fashionable shoes or both ?\n",
      "= i m a mixture of both . seems like the big money i spend for nice shoes ends up being a waste though because then i don t wear the shoes . lol\n",
      "< i m a of of something . of something my car had a lot of money to make for them . i wonder if they were the internet though . <EOS>\n",
      "\n",
      "> i heard that about bk that was funny ! i have always wondered id myspace ever regretted turning down an offer to buy facebook now that they so huge now . . . .crazy how things work out .\n",
      "= it is . it is so accepted as communication that iceland is rewriting their constitution using facebook so that people can make suggestions and or changes .\n",
      "< it is so much it . . that is so much so much so long . <EOS>\n",
      "\n",
      "> i did not know that that is a cool fact . too bad it was discontinued in japan in \n",
      "= do you like bill nye the science guy ?\n",
      "< well it is a great do you do know that ? in the <EOS>\n",
      "\n",
      "> and even they don t attack as often as people think .\n",
      "= nope they have actually rescued sailors .\n",
      "< i don t think that s a great . <EOS>\n",
      "\n",
      "> they are set in the s ? i thought it was supposed to be present times . ill have to look at that .\n",
      "= it s worth watching ! it is a pixar film that was distributed by disney studios and directed by brad bird . also samuel l . jackson has a role in it as well !\n",
      "< it is be very a lot ! it is of be or that they were pretty popular . i wonder if they were the internet something <EOS>\n",
      "\n",
      "> money in the game certainly has changed also . in the s bowling pros mad more money than football stars .\n",
      "= wow thats the opposite of today how would you feel if you walked into a locker room and it was pink ? the university of iowa actually did that to the opposing team\n",
      "< wow thats the opposite of the you did you you know that the ? and in the <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACG4Q06bkf-z"
   },
   "source": [
    "Exercises\n",
    "=========\n",
    "\n",
    "-  Try with a different dataset\n",
    "\n",
    "   -  Another language pair\n",
    "   -  Human → Machine (e.g. IOT commands)\n",
    "   -  Chat → Response\n",
    "   -  Question → Answer\n",
    "\n",
    "-  Replace the embeddings with pre-trained word embeddings such as word2vec or\n",
    "   GloVe\n",
    "-  Try with more layers, more hidden units, and more sentences. Compare\n",
    "   the training time and results.\n",
    "-  If you use a translation file where pairs have two of the same phrase\n",
    "   (``I am test \\t I am test``), you can use this as an autoencoder. Try\n",
    "   this:\n",
    "\n",
    "   -  Train as an autoencoder\n",
    "   -  Save only the Encoder network\n",
    "   -  Train a new Decoder for translation from there\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cXeLJunHBsjD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seq2seq_bot.ipynb\"",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "061670ab7df04ec59ac89a79141d5773": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ad9f6135f4b4405b5facba733d28865": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0db735ce391a424c87a3f287340ab7fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f35c10168a74023b503c589e0a3e48e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a279709b86e47e6b44117900e352dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2392865fc8646509d45a5bfcdbdaad5",
       "IPY_MODEL_9d1ff43c43ee4dfd9d3d6db33f3fef7f",
       "IPY_MODEL_5bf2e4b9333d4909b661e69dc5e5bb5c"
      ],
      "layout": "IPY_MODEL_061670ab7df04ec59ac89a79141d5773"
     }
    },
    "1ecd56e5cd334e90ac1963e6255723b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ea006d2693a46b7a6f73ad98c3ad71f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0f35c10168a74023b503c589e0a3e48e",
      "placeholder": "​",
      "style": "IPY_MODEL_ed65250433ee4013acda7747b672123b",
      "value": "Downloading: 100%"
     }
    },
    "37b45c0d2e3f421f8f8dba60722b1762": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "489ea138854d48008e1904c9e46dd6c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5bf2e4b9333d4909b661e69dc5e5bb5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa1455eaad504e11b44f2a9ca79a6697",
      "placeholder": "​",
      "style": "IPY_MODEL_63a6cde631a947a6bb85d1cbb89d9f21",
      "value": " 446k/446k [00:00&lt;00:00, 683kB/s]"
     }
    },
    "5bf945ae3c7540f6ba472f20e2fdacb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7129a21f55af4ccb8bb7544ee34b6831",
       "IPY_MODEL_ffe6cf8b83c649ec8aa08d270316b730",
       "IPY_MODEL_c3382ae68dd84a4ba848cf70807658e0"
      ],
      "layout": "IPY_MODEL_0db735ce391a424c87a3f287340ab7fa"
     }
    },
    "5e76746f82b5427ab86238f4af8f0990": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a688e92efa5740e3ae9a4dc973a06df8",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fecd7f53f93644bfa8c70dc8946a7919",
      "value": 665
     }
    },
    "5f0035855dfe4cd597ee7030acf16d72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63a6cde631a947a6bb85d1cbb89d9f21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69de0ae6cbbe4eb7812e5884318d20b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6a228332a0f44ba29f6e211f43c884a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e6527f3e6c24c69ab4d669c28207a84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7129a21f55af4ccb8bb7544ee34b6831": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69de0ae6cbbe4eb7812e5884318d20b6",
      "placeholder": "​",
      "style": "IPY_MODEL_6e6527f3e6c24c69ab4d669c28207a84",
      "value": "Downloading: 100%"
     }
    },
    "7740d64e27724da6ba665101cbe4fd74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7fe87edbe4a945e3b48b4640aefc9aa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9002278fd22143c69a6ab1dd360bcbcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d1ff43c43ee4dfd9d3d6db33f3fef7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ad9f6135f4b4405b5facba733d28865",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ecd56e5cd334e90ac1963e6255723b6",
      "value": 456318
     }
    },
    "a688e92efa5740e3ae9a4dc973a06df8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3382ae68dd84a4ba848cf70807658e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f2f168b45b1745a3ac7fb3c21699faa9",
      "placeholder": "​",
      "style": "IPY_MODEL_37b45c0d2e3f421f8f8dba60722b1762",
      "value": " 0.99M/0.99M [00:00&lt;00:00, 2.39MB/s]"
     }
    },
    "df887e109e674daeb07ea2a6a9291202": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed65250433ee4013acda7747b672123b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efc568a8b8644795b1ac2e3e6a533a3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df887e109e674daeb07ea2a6a9291202",
      "placeholder": "​",
      "style": "IPY_MODEL_7740d64e27724da6ba665101cbe4fd74",
      "value": " 665/665 [00:00&lt;00:00, 16.9kB/s]"
     }
    },
    "f2392865fc8646509d45a5bfcdbdaad5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a228332a0f44ba29f6e211f43c884a7",
      "placeholder": "​",
      "style": "IPY_MODEL_9002278fd22143c69a6ab1dd360bcbcf",
      "value": "Downloading: 100%"
     }
    },
    "f2f168b45b1745a3ac7fb3c21699faa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f60dee956d9d444f98a69ea9a6c8f17d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ea006d2693a46b7a6f73ad98c3ad71f",
       "IPY_MODEL_5e76746f82b5427ab86238f4af8f0990",
       "IPY_MODEL_efc568a8b8644795b1ac2e3e6a533a3c"
      ],
      "layout": "IPY_MODEL_7fe87edbe4a945e3b48b4640aefc9aa0"
     }
    },
    "fa1455eaad504e11b44f2a9ca79a6697": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fecd7f53f93644bfa8c70dc8946a7919": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ffe6cf8b83c649ec8aa08d270316b730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f0035855dfe4cd597ee7030acf16d72",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_489ea138854d48008e1904c9e46dd6c1",
      "value": 1042301
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
